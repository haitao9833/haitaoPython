{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1de734",
   "metadata": {},
   "source": [
    "# 默认代码\n",
    ">- `filePath` 需要带文件后缀 `.txt` 或 `.xlsx` 或 `.json`\n",
    ">- 除了读取操作，其他任何操作都不要在打开文件的情况下进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入形式\n",
    "\n",
    "# %%capture\n",
    "# %run \"file_Tool.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只要导入了 file_Tool.ipynb ，则不再需要重复导入这些包\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d18e3",
   "metadata": {},
   "source": [
    "# Text\n",
    ">- `DataFrame` $\\Leftrightarrow$ `.txt` 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658718e9",
   "metadata": {},
   "source": [
    "## 写入\n",
    ">- 将 `List` 元素一行一行地写入 `.txt` 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7820ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .txt 文件不存在：自动创建，并写入\n",
    "# .txt 文件存在时：直接覆盖\n",
    "\n",
    "def cover_txt(lines , filePath):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    with open(filePath , 'w' , encoding = 'utf-8') as file:\n",
    "        for line in lines:\n",
    "            file.write(str(line))\n",
    "            file.write('\\n')\n",
    "    \n",
    "    if E:\n",
    "        print(f\"文件存在，直接覆盖 '{filePath}'\")\n",
    "    else:\n",
    "        print(f\"文件不存在，自动创建，并写入 '{filePath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a108858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .txt 文件不存在：自动创建，并写入\n",
    "# .txt 文件存在时：末尾追加\n",
    "\n",
    "def append_txt(lines , filePath):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    with open(filePath , 'a' , encoding = 'utf-8') as file:\n",
    "        \n",
    "        # 存在\n",
    "        if E:\n",
    "            file.write('\\n-----追加-----\\n')\n",
    "            \n",
    "        for line in lines:\n",
    "            file.write(str(line))\n",
    "            file.write('\\n')\n",
    "    \n",
    "    if E:\n",
    "        print(f\"文件存在，末尾追加 '{filePath}'\")\n",
    "    else:\n",
    "        print(f\"文件不存在，自动创建，并写入 '{filePath}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f15729",
   "metadata": {},
   "source": [
    "## 读取\n",
    ">- `.txt` 文件必须已经存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a318a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回 lines == ['第一行' , '第二行' , '第三行' , ...]\n",
    "\n",
    "def read_txt(filePath):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    if E:\n",
    "        with open(filePath , 'r' , encoding = 'utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            lines = [line.strip() for line in lines]                       # 去除每一行首尾的：空白 + \\n + \\r + \\t\n",
    "            lines = [line for line in lines if (len(line) != 0)]           # 去除空字符串\n",
    "            lines = [line for line in lines if (line.isspace() != True)]   # 去除空白行\n",
    "            return lines\n",
    "    else:\n",
    "        print(f\"指定的文件 '{filePath}' 不存在！！！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5608f1b",
   "metadata": {},
   "source": [
    "# Excel\n",
    ">- `DataFrame` $\\Leftrightarrow$ `.xlsx` 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8bc13",
   "metadata": {},
   "source": [
    "## 单 sheet\n",
    ">- 注意：`List`  ==>  存储  ==>  Excel  ==>  读取  ==> `String`（详见 `file_Tool_Test.ipynb`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b9cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .xlsx 文件不存在：自动创建，并写入（sheetName 默认命名为 Sheet1）\n",
    "# .xlsx 文件存在时：直接覆盖（多个原先的 sheet 会被全部删除，仅有一个覆盖后的 Sheet1）\n",
    "\n",
    "def save_ex(data , filePath):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    # 修改 data 的行索引名称，方便下面保存为一列数据\n",
    "    data.index.name = 'Index'\n",
    "    \n",
    "    # index = True 表明将 data 的行索引也作为一列数据保存，方便到时候 data = data.set_index('Index') 重置行索引\n",
    "    data.to_excel(filePath , index = True)\n",
    "    \n",
    "    if E:\n",
    "        print(f\"文件存在，直接覆盖 '{filePath}'\")\n",
    "    else:\n",
    "        print(f\"文件不存在，自动创建，并写入 '{filePath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可用于读取多 sheet 的 .xlsx 文件，默认仅读取第一个 sheet\n",
    "\n",
    "def read_ex(filePath):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    if E:\n",
    "        res = pd.read_excel(filePath)\n",
    "        return res\n",
    "    else:\n",
    "        print(f\"指定的文件 '{filePath}' 不存在！！！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a962a",
   "metadata": {},
   "source": [
    "## 多 sheet\n",
    ">- 仅读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回所有 sheetName 组成的 List\n",
    "\n",
    "def read_all_sheets(filePath):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    if E:\n",
    "        return openpyxl.load_workbook(filePath).sheetnames\n",
    "    else:\n",
    "        print(f\"指定的文件 '{filePath}' 不存在！！！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a261cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取指定的 sheetName ，单 sheetName 也适用\n",
    "\n",
    "def read_ex_sheet(filePath , sheetName):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    if E:\n",
    "        res = pd.read_excel(filePath , sheetName)\n",
    "        return res\n",
    "    else:\n",
    "        print(f\"指定的文件 '{filePath}' 不存在！！！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b6908",
   "metadata": {},
   "source": [
    "# Json\n",
    ">- `DataFrame` $\\Leftrightarrow$ `.json` 文件\n",
    ">  - 最外面是 `[]`\n",
    ">  - 里面一个一个是 `{}, ...`\n",
    ">  - 再里面一个一个是 `\"key\" : \"value\", ...`\n",
    ">  - 若 `value` 是数值或 `List` ，则没有双引号 `\"` 括起来\n",
    ">- `orient = 'records'`\n",
    ">  - `DataFrame` 的一行  ==  一个 `{}`\n",
    ">  - 不包括行索引 index\n",
    ">- 注意一：`List`  ==>  存储  ==>  JSON  ==>  读取  ==> `List`（区别于上述的 Eecel）\n",
    ">- 注意二：存储的字符串带有 `/` 时，会在 `.json` 文件中显示为 `\\/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接覆盖\n",
    "\n",
    "def save_json(data , filePath):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    # 设置参数 force_ascii = False 确保中文不乱码\n",
    "    data.to_json(filePath , orient = 'records' , force_ascii = False)\n",
    "    \n",
    "    if E:\n",
    "        print(f\"文件存在，直接覆盖 '{filePath}'\")\n",
    "    else:\n",
    "        print(f\"文件不存在，自动创建，并写入 '{filePath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3582bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filePath):\n",
    "    \n",
    "    # 判断文件是否存在\n",
    "    E = os.path.exists(filePath)\n",
    "    \n",
    "    if E:\n",
    "        res = pd.read_json(filePath , orient = 'records')\n",
    "        return res\n",
    "    else:\n",
    "        print(f\"指定的文件 '{filePath}' 不存在！！！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d99f5",
   "metadata": {},
   "source": [
    "# 各类统计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe4d71",
   "metadata": {},
   "source": [
    "## 每列的数据类型\n",
    ">- 比单纯的 `data.dtypes` 要更加详细\n",
    ">- 详见 `README_Soft` 的 `WPS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4166ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allCols(data):\n",
    "    \n",
    "    print('----------------------')\n",
    "    \n",
    "    # (行 , 列)\n",
    "    print(data.shape)\n",
    "    \n",
    "    print('-------------------------------------------------------------------')\n",
    "    \n",
    "    cols = data.columns.values\n",
    "    # print(f'{str(type(cols)):<25s}     {cols}')\n",
    "    # 所有列名组成的 numpy.ndarray\n",
    "    \n",
    "    for c in cols:\n",
    "        print(f'{str(type(data.iloc[0][c])):>25s}     {c:<10s}')\n",
    "    \n",
    "    print('-------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207de053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有列的数据类型作为 List 返回，方便一些判断\n",
    "# 收集的结果可以直接用 == 或 in 作判断，例如下面的搜索列值\n",
    "# 同时注意 np. 和 pd. 缩写前缀即可，具体见 file_Tool_Test.ipynb 的测试数据类型\n",
    "\n",
    "def allCols_simple(data):\n",
    "    \n",
    "    cols = data.columns.values\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for c in cols:\n",
    "        res.append(type(data.iloc[0][c]))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a8521",
   "metadata": {},
   "source": [
    "## 每列的 `NaN` 值分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allNaN(data):\n",
    "    \n",
    "    nullData = pd.DataFrame()\n",
    "    nullData['列'] = data.columns.values\n",
    "    nullData['NaN 个数'] = data.isnull().sum().values\n",
    "    nullData['NaN 占比'] = (data.isnull().sum() / len(data)).values\n",
    "    \n",
    "    display(nullData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba381bc6",
   "metadata": {},
   "source": [
    "## 列值统计\n",
    ">- 忽略 `NaN` 值，即不会统计 `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eec2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colName 为 String\n",
    "\n",
    "def val_cnt(data , colName):\n",
    "    \n",
    "    res = data[colName].value_counts().reset_index()\n",
    "    res.columns = [colName , 'cnt']\n",
    "    \n",
    "    # 按 cnt 降序排列\n",
    "    res = res.sort_values(by = 'cnt' , ascending = False)\n",
    "    \n",
    "    # 占比\n",
    "    res['proportion'] = res.apply(lambda row : f\"{(row['cnt'] / sum(res['cnt'])):6.2%}\" , axis = 1)\n",
    "    \n",
    "    # 汇总\n",
    "    # res = res.append(pd.Series({colName : '' , 'cnt' : sum(res['cnt']) , 'proportion' : ''} , name = 'ALL'))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b624b1",
   "metadata": {},
   "source": [
    "## `int` 列绘统计\n",
    ">- 制条形图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e34eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col 为 DataFrame 的一列 Series 且为 int 数值类型\n",
    "\n",
    "def val_cnt_int(data , colName):\n",
    "    \n",
    "    res = val_cnt(data , colName)\n",
    "    \n",
    "    fig = px.bar(res , \n",
    "                 x = f'{colName}', \n",
    "                 y = 'cnt' , \n",
    "                 #title = f'{colName} 值分布'\n",
    "                 )\n",
    "    fig.show()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ec960",
   "metadata": {},
   "source": [
    "## 比较两列\n",
    ">- 适用于 `int` 列或 `String` 列\n",
    ">- [px 的使用]https://www.cnblogs.com/Mangnolia/p/14308471.html\n",
    ">- [px 的使用]https://blog.csdn.net/qq_25443541/article/details/115603480\n",
    ">- [px 的使用]https://blog.csdn.net/lemonbit/article/details/119012201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9669465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int == int\n",
    "# String == String\n",
    "\n",
    "def isSame(a, b):\n",
    "    if a == b:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col1 为 DataFrame 的一列 Series ，即 data['列名']\n",
    "# col2 为 DataFrame 的一列 Series ，即 data['列名']\n",
    "\n",
    "def diff_Pie(col1 , col2):\n",
    "    \n",
    "    # 两列拼凑在一起，比较 True 或 False\n",
    "    tab = pd.DataFrame()\n",
    "    tab[col1.name] = col1.values\n",
    "    tab[col2.name] = col2.values\n",
    "    tab['same'] = tab.apply(lambda row : isSame(row[col1.name] , row[col2.name]) , axis = 1)\n",
    "    \n",
    "    # 统计 True 和 False\n",
    "    res = tab['same'].value_counts().reset_index()\n",
    "    res.columns = ['same' , 'cnt']\n",
    "    display(res)\n",
    "    \n",
    "    fig = px.pie(\n",
    "        res ,\n",
    "        names = 'same',        # 划分块，即每个扇形的意义\n",
    "        values = 'cnt',        # 算占比，即每个扇形的占比\n",
    "        # title = f'Are the [{col1.name}] as same as the [{col2.name}] ?' , \n",
    "    )\n",
    "    \n",
    "    # 文本信息水平显示\n",
    "    fig.update_traces(textposition = 'inside', \n",
    "                      textinfo = 'percent+label' , \n",
    "                      insidetextorientation = 'horizontal')\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # return tab , res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d24cfa",
   "metadata": {},
   "source": [
    "# 搜索列值\n",
    ">- 对于完整的列值进行 `==` 或 `<` 等，可见 `base_Pandas.ipynb` 的筛选访问\n",
    ">- 对于列值的子部分进行搜索，需要用到如下函数，适用于 `String` 列或 `List` 列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ec1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 data 的 trgC 列中搜索 sub 内容\n",
    "\n",
    "# 传入参数一：（推荐）\n",
    "# 在传入 data 时，可以少传入几列，仅传入想看到的列\n",
    "# 例如 data[['想看到的列' , '想看到的列' , ...]] ，而且此时为副本传入，见 base_Pandas.ipynb 的切片视图测试\n",
    "\n",
    "# 传入参数二：\n",
    "# 若传入整个 data ，则是在原 data 上添加了 exist 列\n",
    "# 除非传入时使用 data.copy() ，避免在原 data 上添加 exist 列\n",
    "\n",
    "def find_sub(data , trgC , sub):\n",
    "    \n",
    "    data['exist'] = data.apply(lambda row : sub in row[trgC] , axis = 1)\n",
    "    \n",
    "    return data[data['exist'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subs = List = [sub , sub , ...]\n",
    "# 注意，若列值中出现多个 sub ，则该行会重复拼接到 res 中，可依据行索引观察到\n",
    "\n",
    "def find_subs(data , trgC , subs):\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    \n",
    "    for sub in subs:\n",
    "        res = pd.concat([res , find_sub(data , trgC , sub)] , axis = 0)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422da82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上述 find_subs 的重置行索引，且去重\n",
    "# 注意\n",
    "\n",
    "def find_subs_nodul(data , trgC , subs):\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    \n",
    "    for sub in subs:\n",
    "        res = pd.concat([res , find_sub(data , trgC , sub)] , axis = 0)\n",
    "    \n",
    "    # 去重\n",
    "    if list in allCols_simple(res):\n",
    "        print(f'含有 List 列，无法去重，仅能重置行索引！！！')\n",
    "    else:\n",
    "        res = res.drop_duplicates()\n",
    "    \n",
    "    # 重置行索引为从 0 开始的整数\n",
    "    res = res.reset_index(drop = True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316c86e",
   "metadata": {},
   "source": [
    "# 标准化\n",
    ">- 不同列的量级差距太大"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f49c37",
   "metadata": {},
   "source": [
    "## `min-max`\n",
    ">- $x \\rightarrow \\frac{x - min}{max - min} \\in [0 , 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 max 和 min ，将数据转换到 [0 , 1] 范围内\n",
    "# 数据中原 min 转换为 0\n",
    "# 数据中原 max 转换为 1\n",
    "\n",
    "# 参数必须得是 DataFrame\n",
    "\n",
    "def standardize_min_max(data):\n",
    "    \n",
    "    # 二维 ndarray\n",
    "    # return MinMaxScaler().fit_transform(data)\n",
    "\n",
    "    return pd.DataFrame(MinMaxScaler().fit_transform(data) , columns = data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef55532e",
   "metadata": {},
   "source": [
    "## `z-score`\n",
    ">- $x \\rightarrow \\frac{x - \\mu}{\\sigma}$\n",
    ">  - 均值为 0\n",
    ">  - 方差为 1\n",
    ">- 注意\n",
    ">  - 不会改变原始数据的分布\n",
    ">  - 原始数据是正态分布就依旧是正态分布\n",
    ">  - 原始数据不是就不是\n",
    ">  - 所以那些说这个操作使得数据变为 0-1 正态分布的说法是错误的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数必须得是 DataFrame\n",
    "\n",
    "def standardize_mean_var(data):\n",
    "    \n",
    "    # 二维 ndarray\n",
    "    # return StandardScaler().fit_transform(data)\n",
    "\n",
    "    return pd.DataFrame(StandardScaler().fit_transform(data) , columns = data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc8108",
   "metadata": {},
   "source": [
    "# 相似性\n",
    ">- 见 `数学.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d05aa",
   "metadata": {},
   "source": [
    "## 欧氏距离\n",
    ">- `np.linalg.norm(vec)` 默认即求 `L2` 范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eefbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以传入 DataFrame 的两行 Series（.iloc[]）\n",
    "# 也可以传入两个 ndarray\n",
    "\n",
    "def similarity_o(vec1 , vec2):\n",
    "    \n",
    "    return np.linalg.norm(vec1 - vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1979266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求 DataFrame 每一行之间的欧氏距离\n",
    "# 也可以传入二维 ndarray\n",
    "\n",
    "def similarity_o_all(data):\n",
    "    \n",
    "    n = len(data)\n",
    "    \n",
    "    arr = np.zeros((n , n))\n",
    "    for i in range(0 , n):\n",
    "        for j in range(0 , n):\n",
    "            if type(data) == pd.core.frame.DataFrame:\n",
    "                arr[i , j] = similarity_o(data.iloc[i] , data.iloc[j])\n",
    "            elif type(data) == np.ndarray:\n",
    "                arr[i , j] = similarity_o(data[i] , data[j])\n",
    "    \n",
    "    res = pd.DataFrame(arr)\n",
    "    \n",
    "    # 对称矩阵\n",
    "    if type(data) == pd.core.frame.DataFrame:\n",
    "        res.columns = data.index\n",
    "        res.index = data.index\n",
    "    elif type(data) == np.ndarray:\n",
    "        res.columns = [f'vec{i}' for i in range(1 , data.shape[0] + 1)]\n",
    "        res.index = [f'vec{i}' for i in range(1 , data.shape[0] + 1)]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9368de1",
   "metadata": {},
   "source": [
    "## 余弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532082b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e208570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求 DataFrame 每一行之间的余弦相似度\n",
    "# 也可以传入二维 ndarray\n",
    "\n",
    "def similarity_cos_all(data):\n",
    "    \n",
    "    # 计算\n",
    "    res = pd.DataFrame(cosine_similarity(data))\n",
    "    \n",
    "    # 对称矩阵\n",
    "    if type(data) == pd.core.frame.DataFrame:\n",
    "        res.columns = data.index\n",
    "        res.index = data.index\n",
    "    elif type(data) == np.ndarray:\n",
    "        res.columns = [f'vec{i}' for i in range(1 , data.shape[0] + 1)]\n",
    "        res.index = [f'vec{i}' for i in range(1 , data.shape[0] + 1)]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268c005",
   "metadata": {},
   "source": [
    "## 余弦距离\n",
    "> 余弦距离 `==` 1 - 余弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求 DataFrame 每一行之间的余弦距离\n",
    "# 也可以传入二维 ndarray\n",
    "\n",
    "def similarity_cos_dist_all(data):\n",
    "    \n",
    "    # 计算\n",
    "    res = pd.DataFrame(pairwise_distances(data , metric = 'cosine'))\n",
    "    \n",
    "    # 对称矩阵\n",
    "    if type(data) == pd.core.frame.DataFrame:\n",
    "        res.columns = data.index\n",
    "        res.index = data.index\n",
    "    elif type(data) == np.ndarray:\n",
    "        res.columns = [f'vec{i}' for i in range(1 , data.shape[0] + 1)]\n",
    "        res.index = [f'vec{i}' for i in range(1 , data.shape[0] + 1)]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212c77b",
   "metadata": {},
   "source": [
    "## 皮尔逊相关系数\n",
    ">- $r \\in [-1 , 1]$\n",
    ">  - 越接近 `-1` 负相关性越强\n",
    ">  - 越接近 `+1` 正相关性越强\n",
    ">  - 绝对值越大，线性相关性越强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以传入两个 List\n",
    "# 可以传入两个 ndarray\n",
    "# 可以传入 DataFrame 的两行 Series（.iloc[]）\n",
    "\n",
    "def similarity_r(vec1 , vec2):\n",
    "    \n",
    "    corr = pearsonr(vec1 , vec2)\n",
    "    \n",
    "    print(f'相关系数 r = {corr[0]}')\n",
    "    \n",
    "    print(f'显著水平 P = {corr[1]}' , end = '   ')\n",
    "    \n",
    "    # P < 0.05 表示显著相关，相关性真实存在，非偶然情况\n",
    "    if (corr[1] < 0.05):\n",
    "        print(f'（显著相关）')\n",
    "    else:\n",
    "        print(f'（非显著相关）')\n",
    "    \n",
    "    # return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 自带的函数，由于默认计算的是列与列之间的皮尔逊相关系数，所以需要先转置一下 DataFrame\n",
    "\n",
    "# 计算某一行与其他行的皮尔逊相关系数\n",
    "# trgI 为行索引，为 String ，\n",
    "\n",
    "def similarity_r_one(data , trgI):\n",
    "    \n",
    "    # 转置\n",
    "    data = data.copy().T\n",
    "    \n",
    "    # 取出一列 Series\n",
    "    trg = data[trgI]\n",
    "    \n",
    "    # 计算\n",
    "    corr = data.corrwith(trg)\n",
    "    \n",
    "    res = pd.DataFrame(corr , columns = [trgI])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 自带的函数，由于默认计算的是列与列之间的皮尔逊相关系数，所以需要先转置一下 DataFrame\n",
    "\n",
    "# 计算每一行之间的皮尔逊相关系数\n",
    "\n",
    "def similarity_r_all(data):\n",
    "    \n",
    "    # 转置\n",
    "    data = data.copy().T\n",
    "    \n",
    "    return data.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MathBert",
   "language": "python",
   "name": "mathbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217.104px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
